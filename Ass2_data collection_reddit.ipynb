{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a9e863-0132-4f7b-863c-e5f30ea17ac6",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3e2be3-29ae-4ae7-8e3d-01532d00ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Chelsea/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Chelsea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import praw\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import string\n",
    "import codecs\n",
    "import re\n",
    "import praw\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon') \n",
    "nltk.download('wordnet')\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis.lda_model\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5675b5-90a0-4994-9fa0-abeac44847f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redditClient():\n",
    "    \"\"\"\n",
    "        Setup Reedit API authentication.\n",
    "        Replace username, secrets and passwords with your own.\n",
    "\n",
    "        @returns: praw Reedit object\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        clientId = \"wxXd0m1BJeyk8e063RmgIQ\"\n",
    "        clientSecret = \"H5Tup-uhMHVudsDO38hpvXfLn3vbFQ\"\n",
    "        password = \"Chelsea0220\"\n",
    "        userName = \"Ok_Shopping_473\"\n",
    "        userAgents = 'client for SNAM2024'\n",
    "\n",
    "        redditClient = praw.Reddit(client_id = clientId,\n",
    "                                   client_secret = clientSecret,\n",
    "                                   user_agent = userAgents)\n",
    "    except KeyError:\n",
    "        sys.stderr.write(\"Key or secret token are invalid.\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return redditClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feb055aa-af00-4ddd-a726-9fb2fb79e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of submissions found for keyword 'Olympics 2024': 245\n",
      "Number of submissions found for keyword 'Olympics 2020': 228\n",
      "Number of submissions found for keyword 'Olympics 2016': 231\n"
     ]
    }
   ],
   "source": [
    "def fetch_posts(keywords, limit=5000, filename='posts.json'):\n",
    "    reddit = redditClient()\n",
    "    all_posts = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            # Search for submissions containing the keyword\n",
    "            submissions = reddit.subreddit('all').search(keyword, limit=limit)\n",
    "\n",
    "            posts = []\n",
    "            for submission in submissions:\n",
    "                submission_data = {\n",
    "                    'id': submission.id,\n",
    "                    'title': submission.title,\n",
    "                    'selftext': submission.selftext,\n",
    "                    'score': submission.score,\n",
    "                    'created': submission.created_utc,\n",
    "                    'author_id': submission.author.name if submission.author else 'N/A',\n",
    "                    'comments': [],\n",
    "                    'keyword': keyword  # Store the keyword used for the search\n",
    "                }\n",
    "\n",
    "                submission.comments.replace_more(limit=0)\n",
    "                for comment in submission.comments.list():\n",
    "                    comment_data = {\n",
    "                        'id': comment.id,\n",
    "                        'body': comment.body,\n",
    "                        'score': comment.score,\n",
    "                        'created': comment.created_utc,\n",
    "                        'author_id': comment.author.name if comment.author else 'N/A',\n",
    "                    }\n",
    "                    submission_data['comments'].append(comment_data)\n",
    "\n",
    "                posts.append(submission_data)\n",
    "\n",
    "            print(f\"Number of submissions found for keyword '{keyword}': {len(posts)}\")\n",
    "            all_posts.extend(posts)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching posts for keyword '{keyword}': {e}\")\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(all_posts, file, indent=5)\n",
    "\n",
    "# Usage example with keywords\n",
    "keywords = ['Olympics 2024', 'Olympics 2020', 'Olympics 2016']\n",
    "fetch_posts(keywords, limit=5000, filename='olympics_posts.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f7703-837a-4576-9209-2b11b787d9f7",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02d6c40c-8983-4fd2-bcab-4f43e9dcd9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                                              Title  \\\n",
      "0    1ef4lku  USA, a country so obsessed with guns, has so f...   \n",
      "1    1eeaa5m          Most controversial pic from olympics 2024   \n",
      "2    1f5ez3o     Paralympic breakdancing at PARIS Olympics 2024   \n",
      "3    1epqvq1  USA and China tie for most gold medals in the ...   \n",
      "4    1ej4nz8  The kiss between gold medal's winner Alice Bel...   \n",
      "..       ...                                                ...   \n",
      "698   lbvzaf  What's your craziest ride on a skates? Here is...   \n",
      "699   3phyki  Banco Bradesco, 2016 Olympic Sponsor, destroyi...   \n",
      "700   5677r2  All 36 Rio 2016 Olympic boxing referees and ju...   \n",
      "701   4xksxz  Post Match: Nadal vs Del Potro (Semifinal, 201...   \n",
      "702   viebgm  [Stein] There are credible rumblings in circul...   \n",
      "\n",
      "                                              Selftext             Created  \n",
      "0                                                      2024-07-29 16:56:29  \n",
      "1                                                      2024-07-28 15:39:21  \n",
      "2                                                      2024-08-31 04:25:46  \n",
      "3                                                      2024-08-11 17:50:10  \n",
      "4                                                      2024-08-03 14:29:15  \n",
      "..                                                 ...                 ...  \n",
      "698                                                    2021-02-03 19:32:12  \n",
      "699  [PHOTOS from yesterday 10/19.](http://imgur.co... 2015-10-20 14:55:03  \n",
      "700                                                    2016-10-06 19:29:24  \n",
      "701  **2016 Rio Olympics - Semifinal**\\n\\n---\\n\\n##... 2016-08-13 20:19:16  \n",
      "702   [Source](https://marcstein.substack.com/p/kyr... 2022-06-22 20:14:44  \n",
      "\n",
      "[703 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# load json file\n",
    "fJsonName = 'olympics_posts.json'\n",
    "\n",
    "post_data =[]\n",
    "# open json file and process it tweet by tweet\n",
    "with open(fJsonName, 'r') as f:\n",
    "    dSubmissions = json.load(f)\n",
    "    \n",
    "    for submission in dSubmissions[1:]:\n",
    "        submissionID = submission['id']\n",
    "        submissionsTitle = submission['title']\n",
    "        submissionSelftext = submission['selftext']\n",
    "        submissionCreated = submission['created']\n",
    "        submissionAuthor = submission['author_id']\n",
    "\n",
    "        # store all process data\n",
    "        post_data.append({\n",
    "            'ID': submissionID,\n",
    "            'Title': submissionsTitle,\n",
    "            'Selftext': submissionSelftext,\n",
    "            'Created': submissionCreated\n",
    "        })\n",
    "\n",
    "# Convert a DataFrame\n",
    "df_post = pd.DataFrame(post_data)\n",
    "# change datetime\n",
    "df_post['Created'] = pd.to_numeric(df_post['Created'], errors='coerce')\n",
    "df_post['Created'] = pd.to_datetime(df_post['Created'], unit='s')\n",
    "\n",
    "print(df_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3dff442-a003-4b6b-862e-1565a273ddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       submissionID commentID  \\\n",
      "0           1er8uik   lhxbug8   \n",
      "1           1er8uik   lhx5ejr   \n",
      "2           1er8uik   lhy3e0l   \n",
      "3           1er8uik   lhx9nqm   \n",
      "4           1er8uik   lhx0zgh   \n",
      "...             ...       ...   \n",
      "200611       viebgm   iddjjz7   \n",
      "200612       viebgm   iddne1h   \n",
      "200613       viebgm   iddiwjz   \n",
      "200614       viebgm   ide82w7   \n",
      "200615       viebgm   iddptq5   \n",
      "\n",
      "                                              commentBody             Created  \\\n",
      "0       ![gif](giphy|1KHBPmEOkv0B2)\\n\\nPOV: top right ... 2024-08-13 15:41:17   \n",
      "1       I just want to know what's in the top corner o... 2024-08-13 15:07:45   \n",
      "2       I cant believe that this person became\\nthe fo... 2024-08-13 18:05:09   \n",
      "3       Media is more upset about this than the fact t... 2024-08-13 15:29:55   \n",
      "4       Nobody said anything when she lost in the quar... 2024-08-13 14:44:16   \n",
      "...                                                   ...                 ...   \n",
      "200611       Well said, I agree with everything you said. 2022-06-23 01:12:14   \n",
      "200612  I don’t follow his philanthropic efforts. Does... 2022-06-23 01:42:47   \n",
      "200613  Lebron is a billionaire also. He could literal... 2022-06-23 01:06:55   \n",
      "200614  No, as much as the woke hype beasts want to pu... 2022-06-23 04:46:36   \n",
      "200615  I don’t think he’s coming for the MLE but for ... 2022-06-23 02:02:14   \n",
      "\n",
      "                     Author  \n",
      "0            deeeezzzzznuts  \n",
      "1          jigs_after_a_hug  \n",
      "2                  Hobbes10  \n",
      "3                       N/A  \n",
      "4            flibbidygibbit  \n",
      "...                     ...  \n",
      "200611  LittIeLordFuckleroy  \n",
      "200612             jutiatle  \n",
      "200613          ArchAngelN7  \n",
      "200614          Johnsky7788  \n",
      "200615       psychotichorse  \n",
      "\n",
      "[200616 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract comments\n",
    "comments_data = []\n",
    "for post in dSubmissions:\n",
    "    submission_id = post['id']\n",
    "    for comment in post['comments']:\n",
    "        # Include submission ID to link comments to their posts\n",
    "        comments_data.append({\n",
    "            'submissionID': submission_id,\n",
    "            'commentID': comment['id'],\n",
    "            'commentBody': comment['body'],\n",
    "            'Created': comment['created'],\n",
    "            'Author': comment['author_id'],\n",
    "        })\n",
    "# Convert a DataFrame\n",
    "df_comments = pd.DataFrame(comments_data)\n",
    "df_comments['Created'] = pd.to_numeric(df_comments['Created'], errors='coerce')\n",
    "df_comments['Created'] = pd.to_datetime(df_comments['Created'], unit='s')\n",
    "print(df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569bb3be-8115-4618-92ce-0d0cce340637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
